bigram2 <- bigram %>% select (N1, N2, reviews.txt) %>%
filter(reviews.txt > 1)
bigram2 %>% class()
install.packages("igraph")
# バイグラムからネットワークグラフを作るには「igraph」
library(igraph)
bigramN <- graph.data.frame(bigram2)
bigram2 %>% class() # データの型を確認。
# Nグラムデータからネットワークグラフを作るには、ネットワークオブジェクトに変換が必要。
# bigram2オブジェクトは今、データフレーム型なので、ネットワークオブジェクトに変換。
bigramN <- graph.data.frame(bigram2)
bigramN <- graph_from_data_frame(bigram2)
# ネットワークオブジェクトからねとワークグラフを作る。「tkplot」
tkplot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
# ネットワークオブジェクトからねとワークグラフを作る。「tkplot」
tkplot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
# ネットワークオブジェクトからねとワークグラフを作る。「tkplot」
# 「vertex」がプロット上の円。
tkplot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
plot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
plot(bigramN, vertex.color = "SkyBlue", vertex.size = 10)
plot(bigramN, vertex.color = "SkyBlue", vertex.size = 15)
install.packages(ggraph)
install.packages("ggraph")
# ネットワークオブジェクトからねとワークグラフを作る。「tkplot」
# 「vertex」がプロット上の円。
tkplot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
# 「plot」は静的な（画像）プロットを作る。
plot(bigramN, vertex.color = "SkyBlue", vertex.size = 20)
# 「plot」は静的な（画像）プロットを作る。
plot(bigramN, vertex.color = "SkyBlue", vertex.size = 18)
### 7.1 沖縄観光への意見データ
okinawa <- read.csv("data/H18koe.csv")
## 行数を確認
NROW(okinawa)
## 列名を確認
colnames(okinawa)
library(dplyr)
library(magrittr)
View(okinawa)
getwd()
# まずはデータを要約して見る。
# optionは自由記述なので、省く。
okinawa %>% select(Region:Satis) %>% summary()
## データフレームから地域列を削除して上書き。今回の分析では使わない。
okinawa %<>% select(-Region)
## 欠損値を削除
okinawa %<>% na.omit()
okinawa %>% select(Sex:Satis) %>% summary()
okinawa %>% select(Sex:Satis) %>% summary()
okinawa %>% xtabs(~ Sex + Satis , data = .)
# パイプ処理の場合、「data = .」にしなアカン
# xtabsは2変数を指定するが「~ x + y」にのように「~」が必要。
okinawa %>% xtabs( Sex + Satis , data = .)
~
# パイプ処理の場合、「data = .」にしなアカン
# xtabsは2変数を指定するが「~ x + y」にのように「~」が必要。
okinawa %>% xtabs(~ Sex + Satis , data = .)
AgeL <- okinawa %>% use_series(Age) %>% levels()
# パイプ処理の場合、「data = .」にしなアカン
# xtabsは2変数を指定するが「~ x + y」にのように「~」が必要。
okinawa %>% xtabs(~ Sex + Satis , data = .)
library(purrr)
# これから、optionの解析に入る。
AgeL <- okinawa %>% use_series(Age) %>% levels()
AgeL
AgeL %>% map(
~ filter(okinawa, Age == .x) %>% NROW()
)
AgeL %>% map(
~ filter(okinawa, Age == .x) %>% NROW()
)
AgeL %>% map_chr(
~ filter(okinawa, Age == .x) %>% NROW()
)
?NROW()
# map()だと出力はリストで見にくい。
# map_chr()だと、ベクトルで出力してくれる。
AgeL %>% map_chr(
~ filter(okinawa, Age == .x) %>% NROW()
)
AgeL <- AgeL[-1]
library(magrittr)
AgeL %>% map(
~ filter(okinawa, Age  == .x, Sex == "女性") %>% {
tmp <-  use_series(data = ., Opinion) %>% as.character()
writeLines(text = tmp, con = paste0("F", (2:7)[AgeL == .x], "0.txt"))
}
)
AgeL %>% map(
~ filter(okinawa, Age  == .x, Sex == "女性") %>% {
tmp <-  use_series(data = ., Opinion) %>% as.character()
writeLines(text = tmp, con = paste0("F", (2:7)[AgeL == .x], "0.txt"))
}
)
library(RMeCab)
AgeL %>% map(
~ filter(okinawa, Age  == .x, Sex == "女性") %>% {
tmp <-  use_series(data = ., Opinion) %>% as.character()
writeLines(text = tmp, con = paste0("F", (2:7)[AgeL == .x], "0.txt"))
}
)
AgeL %>% map(
~ filter(okinawa, Age  == .x, Sex == "男性") %>% {
tmp <-  use_series(data = ., Opinion) %>% as.character()
writeLines(text = tmp, con = paste0("M", (2:7)[AgeL == .x], "0.txt"))
}
)
AgeL %>% map(
~ filter(okinawa, Age  == .x, Sex == "男性") %>% {
tmp <-  use_series(data = ., Opinion) %>% as.character()
writeLines(text = tmp, con = paste0("M", (2:7)[AgeL == .x], "0.txt"))
}
)
library(RMeCab)
FM <- docDF("okinawa", type = 1,     #type=1は形態素解析。
pos = c("名詞","動詞","形容詞"))
FM <- docDF("data/okinawa", type = 1,     #type=1は形態素解析。
pos = c("名詞","動詞","形容詞"))
FM2 <- FM %>% filter(POS2 %in% c("一般", "固有", "自立"))
# 形態素から、必要な単語のみを抽出。
FM2 <- FM %>% filter(POS2 %in% c("一般", "固有", "自立"))
View(FM2)
FM2 %>% NROW()
# 動詞の自立語には、「ある」「いう」「できる」「思う」など不要な単語も入っている。
# これらを削除するには、「!」と「%in%」を使う。
FM2 <- FM2 %>% filter(! TERM %in% c("ある","いう","いる", "する",
"できる", "なる","思う"))
FM2 %>% NROW()
# 整えたテキストデータから、単語文書行列を作る。
FM <- docDF("data/okinawa", type = 1,     #type=1は形態素解析。
pos = c("名詞","動詞","形容詞"))
# 形態素から、必要な単語のみを抽出。
FM2 <- FM %>% filter(POS2 %in% c("一般", "固有", "自立"))
# 動詞の自立語には、「ある」「いう」「できる」「思う」など不要な単語も入っている。
# これらを削除するには、「!」と「%in%」を使う。
FM2 <- FM2 %>% filter(! TERM %in% c("ある","いう","いる", "する",
"できる", "なる","思う"))
FM2 %>% NROW()
FM2$SUMS <- rowSums(FM2[, -(1:3)])
View(FM2)
# 「$」は添字。FM2の単語文書行列に「SUMS」という列を新規追加。
# rowSumsは各行の合計を求める。SUMS列に代入。
# 1，2，3列目は形態素と品詞の情報なので除外。
FM2$SUMS <- rowSums(FM2[, -(1:3)])
summary(FM2$SUMS)
# 今回は7回以上の単語のみ抽出するが、数字はデータによる。
FM3 <- FM2 %>% filter(SUMS >= 7)
FM3 %>% NROW
colnames((FM3))
# 今回は7回以上の単語のみ抽出するが、数字はデータによる
# 各行の合計をSUMSに入れているので、7回は、「男女20～70代全部の合計で7回以上使われた単語」という意味
FM3 <- FM2 %>% filter(SUMS >= 7)
FM3 %>% NROW
colnames((FM3))
FM3$TERM
View(FM3)
FM3$TERM[168]
library(stringr)
## 正規表現で数値列だけを取り出す
FM4 <- FM3 %>% select(matches("[FM]\\d\\d"))
## 正規表現で数値列だけを取り出す
FM4 <- FM3 %>% select(matches("[FM]\\d\\d"))
## 列名を設定
colnames(FM4) <- str_extract(colnames(FM4), "[FM]\\d\\d")
View(FM4)
## 列名を設定
colnames(FM4) <- str_extract(colnames(FM4), "[FM]\\d\\d")
## 列名を設定
colnames(FM4) <- str_extract(colnames(FM4), "[FM]\\d\\d")
## 行列の名前を設定
rownames(FM4) <- FM3$TERM
View(FM4)
View(FM4)
## 行列の名前を設定
rownames(FM4) <- FM3$TERM
## 次元(行数と列数)を確認
dim(FM4)
## 列名と行名を確認
colnames(FM4)
rownames(FM4)
## 行列の名前を設定
rownames(FM4) <- FM3$TERM
### 7.3 意見データの対応分析
install.packages(c("FactoMineR", "factoextra"))
library(FactoMineR)
## ggplot2 ベースのバイプロットを描く
library(factoextra)
fviz_ca_biplot(FM4ca)
# 対応分析はCA
FM4ca <- CA(FM4, graph = FALSE)
fviz_ca_biplot(FM4ca)
# 対応分析はCA。CAは対応分析だけでなく、独自にバイプロットも作成する。
# 今回は、ggplot2で作りたいから、「graph = FALSE」にする。
FM4ca <- CA(FM4, graph = FALSE)
## ggplot2 ベースのバイプロットを描く
library(factoextra)
fviz_ca_biplot(FM4ca)
# 上記の実行結果の画像で文字化けが生じている場合、以下のようにPDF画像として作成して確認してみてください
# 3行続けて実行することで画像ファイルが作成されます
# RStudio 右のFilesタブで画像ファイルをクリックすることで、適切なビューワー が立ちあがります
cairo_pdf("FM4ca.pdf", family = "JP1")# Mac の場合は family = "HiraKakuProN-W3" と変えてください
fviz_ca_biplot(FM4ca)
dev.off()
## 正規表現で数値列だけを取り出す
# matches()は指定された文字列と一致する列だけ取り出す。
# [FM]はFかMで始まり、「\\d\\d」は数字が2つ続く。
FM4 <- FM3 %>% select(matches("[FM]\\d\\d"))
## 列名を設定
colnames(FM4) <- str_extract(colnames(FM4), "[FM]\\d\\d")
## 行列の名前を設定
rownames(FM4) <- FM3$TERM
## 次元(行数と列数)を確認
dim(FM4)
## 列名と行名を確認
colnames(FM4)
rownames(FM4)
fviz_ca_biplot(FM4ca)
### 独立性の検定(カイ自乗検定)
# Excel ファイルの読み込み
library(readxl)
dat <- read_excel("data/sentences.xlsx")
## クロス表を生成
dat_tb <- xtabs(~ Sex + Sent, data = dat)
dat_tb
options("digits" = 7)
chisq.test(dat_tb)
### 対応分析
dat <- matrix(c(1,2,0,0,  0,2,6,0, 0,1,2,2,  0,0,0,2),
ncol = 4, byrow = TRUE)
colnames(dat) <- c("中卒F", "高校中退F", "高卒F", "大卒F")
rownames(dat) <- c("中卒M", "高校中退M", "高卒M", "大卒M")
View(dat)
View(data01)
dat
datCA <- CA(dat, graph = FALSE)
fviz_ca_biplot(datCA)
dat_cp <- MASS::corresp(dat, nf = 2)
biplot(dat_cp)
# 「corresp」はMASSライブラリの関数である。
# しかし、MASSライブラリはdplyrライブラリと一部、衝突するので、読み込まない。
# 「：：」を使って、特定の関数だけ読み込む。
dat_cp <- MASS::corresp(dat, nf = 2)
biplot(dat_cp)
### 8.1 ダウンロードしたファイルの整形と解析
source("http://rmecab.jp/R/Aozora.R")
Aozora
x <- Aozora("http://www.aozora.gr.jp/cards/000081/files/43754_ruby_17594.zip")
library(RMeCab)
setwd("/home/ishida/Dropbox/R/Morikita/Version2/")
miyaz <- docDF("data/NORUBY/chumonno_oi_ryoriten2.txt", type = 1)
miyaz <- docDF(x, type = 1)
library(dplyr)
miyaz %>% head()
View(miyaz)
miyaz %>% filter(POS2 == "固有名詞")
# まずは、全ての列名を抽出して、それから、POSで必要な品詞のみを抽出。
# そして、頻度列だけ列名を変える。
miyaz2 <- miyaz %>% select(everything(), FREQ = chumonno_oi_ryoriten2.txt) %>%
filter(POS1 %in% c("名詞","形容詞"),
POS2 %in% c("一般", "固有名詞", "自立"))
miyaz2 %>% arrange(FREQ) %>% tail(50)
## ワードクラウドを作成する準備
install.packages("wordcloud")
###### ワードクラウドを作成する準備
# install.packages("wordcloud")
library(wordcloud)
## プロット作成
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(8, "Dark2"))
## プロット作成
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(8, "Dark2"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(80, "Red"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(10, "Red"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(10, "Red2"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(8, "Red"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(8, "Dark2"))
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1")
## プロット作成
# min.freqは頻度の最小値。
# scaleは文字の最大・最小の大きさ
# familyは文字指定。
# brewer.palでカラーパレットを作成。
wordcloud(miyaz2$TERM, miyaz2$FREQ, min.freq = 3,
scale = c(6,1),family = "JP1", colors = brewer.pal(8, "Dark2"))
########### ネットワークグラフ
bigram <- NgramDF("data/NORUBY/chumonno_oi_ryoriten2.txt", type = 1,
pos = c("名詞","形容詞", "動詞"))
bigram <- NgramDF(x, type = 1, pos = c("名詞","形容詞", "動詞"))
bigram %>% head()
bigram2 <- docDF("data/NORUBY/chumonno_oi_ryoriten2.txt", type = 1, N = 2,
pos = c("名詞","形容詞", "動詞"), nDF = 1)
bigram2 <- docDF("data/NORUBY/chumonno_oi_ryoriten2.txt", type = 1, N = 2,
pos = c("名詞","形容詞", "動詞"), nDF = 1)
bigram2 %>% head()
library(magrittr)
bigram2 %>% use_series(POS2) %>% unique()
bigram2 %>% filter(POS2 == "数-数")
bigram2 %>% filter(POS2 == "代名詞-接尾")
bigram3 <- bigram2 %>% select(everything(),
FREQ = chumonno_oi_ryoriten2.txt) %>%
filter(!grepl("数|接尾|非自立", POS2) | FREQ > 5)
View(bigram3)
bigram3 %>% NROW()
bigram3 %>% head()
# bigram3では、品詞細分類が「数」「接尾」「非自立」を削除した。
# bigram4で、頻度2以上のみを抽出。
bigram4 <- bigram3 %>% select (N1, N2, FREQ) %>%
filter(FREQ >= 2)
bigram4 %>% NROW()
bigram4 %>% filter(FREQ == max(FREQ))
bigram5 <- bigram4 %>% filter(FREQ < 25)
library(igraph)
## ネットワークグラフを作るには、データ形式がネットワークグラフ形式でなければならない。
## graph_from_data_frameは、データフレームをネットワークグラフ形式に変換する関数。
bigram6 <- graph_from_data_frame(bigram5)
# ネットワークグラフ形式になったデータをプロットする。（インタラクティブ）
tkplot(bigram6, vertex.color = "SkyBlue", vertex.size = 22)
E(bigram6)$weight <- bigram5$FREQ *2
E(bigram6)$weight <- bigram5$FREQ *2
bigram7 <- edge.betweenness.community(bigram6,
weights = E(bigram6)$weight,
directed = F)
bigram7 <- edge.betweenness.community(bigram6,
weights = E(bigram6)$weight,
directed = F)
bigram7 <- edge.betweenness.community(bigram6,
weights = E(bigram6)$weight,
directed = F)
plot(bigram6, vertex.color = "SkyBlue", vertex.size = 6,
vertex.label.cex  = 1.5, ## 形態素のサイズ
vertex.label.dist = .5,  ## ラベル（単語）を円の外に表示。円のサイズが小さいので、単語がはみ出ると見にくくなる。だから、元から外に表示。
edge.width = E(bigram6)$weight, ## 辺のサイズを調整
vertex.label.family = "JP1") ## フォントの指定
bigram7 <- edge.betweenness.community(bigram6,
weights = E(bigram6)$weight,
directed = F)
plot(bigram7, bigram6, vertex.label.family = "JP1")# Mac の場合は family = "HiraKakuProN-W3" と変えてください
tkplot(bigram7, bigram6, vertex.label.family = "JP1")# Mac の場合は family = "HiraKakuProN-W3" と変えてください
tkplot(bigram7, bigram6, vertex.label.family = "JP1")# Mac の場合は family = "HiraKakuProN-W3" と変えてください
plot(bigram7, bigram6, vertex.label.family = "JP1")# Mac の場合は family = "HiraKakuProN-W3" と変えてください
library(RMeCab)
getwd()
## Windowsの場合は以下の "data/prime/utf" を "data/prime/sjis" にするなど
## 自身の作業環境にあわせて適宜変更
prime <- docMatrix2("data/prime/sjis", pos = c("名詞","形容詞","動詞"),
weight = "tf*idf*norm")
View(prime)
ncol(prime) ; nrow(prime)
View(prime)
library(stringr)
library(dplyr)
library(magrittr)
# "instSenso.R"
install.packages("Rcmdr",dependencies = TRUE)
View(prime)
chemin = paste(find.package(package="Rcmdr")[1],"/etc",sep="")
menu = readLines(con=paste(chemin,"/Rcmdr-menus.txt",sep=""))
if (any(i <- grep("Add menu for SensoMineR" ,menu))){
lig1 = grep("Add menu for SensoMineR",menu)
lig2 = grep("End add menu for SensoMineR",menu)
if (lig2 == length(menu)) {
menu = menu[1:(lig1-1)]
} else {
menu = menu[c(1:(lig1-1),(lig2+1):length(menu))]
}
}
install.packages("SensoMineR",dependencies = TRUE)
add.menu.senso = readLines("http://sensominer.free.fr/add-menu-senso.txt")
senso = readLines("http://sensominer.free.fr/Rcmdr-senso.r")
writeLines(senso,con=paste(chemin,"/Rcmdr-senso.r",sep=""))
menu = c(menu,add.menu.senso)
writeLines(menu,con=paste(chemin,"/Rcmdr-menus.txt",sep=""))
library(Rcmdr)
chemin = paste(find.package(package="Rcmdr")[1],"/etc",sep="")
menu = readLines(con=paste(chemin,"/Rcmdr-menus.txt",sep=""))
if (any(i <- grep("Add menu for SensoMineR" ,menu))){
lig1 = grep("Add menu for SensoMineR",menu)
lig2 = grep("End add menu for SensoMineR",menu)
if (lig2 == length(menu)) {
menu = menu[1:(lig1-1)]
} else {
menu = menu[c(1:(lig1-1),(lig2+1):length(menu))]
}
}
install.packages("SensoMineR",dependencies = TRUE)
add.menu.senso = readLines("http://sensominer.free.fr/add-menu-senso.txt")
senso = readLines("http://sensominer.free.fr/Rcmdr-senso.r")
writeLines(senso,con=paste(chemin,"/Rcmdr-senso.r",sep=""))
menu = c(menu,add.menu.senso)
writeLines(menu,con=paste(chemin,"/Rcmdr-menus.txt",sep=""))
library(stringr)
library(dplyr)
library(magrittr)
## 列名が長すぎるので短縮する
## 「_general-policy-speech.txt」が不要なので削除。（空白に置き換える）
colnames(prime)  %<>% str_replace("_general-policy-speech.txt", "")
View(prime)
colnames(prime)  %<>% str_replace("(\\d{4})\\d{4}_(\\d{3})", "\\1_\\2")
View(prime)
# \\dは数字。{4}は4回。4回連続数字が並ぶ。
# 4回数字が並び、また4回数字が並び、「_」を挟んで、3回数字が並ぶ文字列を
# 最初の4行と最後の3行だけを取り出す。p61
colnames(prime)  %<>% str_replace("(\\d{4})\\d{4}_(\\d{3})", "\\1_\\2")
View(prime)
### 9.3 所信表明演説のクラスター分析
hc <- prime %>% t %>% dist %>% hclust("ward.D2")
#
install.packages("ggdendro")
library(ggdendro)
?t()
library(ggdendro)
ggdendrogram(hc, rotate= TRUE)
# 上記の実行結果の画像で文字化けが生じている場合、以下のようにPDF画像として作成して確認してみてください
# 3行続けて実行することで画像ファイルが作成されます
# RStudio 右のFilesタブで画像ファイルをクリックすることで、適切なビューワー が立ちあがります
cairo_pdf(file = "hc.pdf", family = "JP1")
ggdendrogram(hc, rotate= TRUE)
dev.off()
TD <- matrix (c(1,0,0,0,1,0,
0,1,0,1,0,1,
0,1,0,0,0,0,
0,1,0,0,0,0,
0,0,1,0,0,1,
1,1,1,1,0,0,
0,0,1,2,1,0,
1,1,0,0,0,0), nrow = 8, byrow = TRUE)
## 作成した行列に列名と行名を設定
colnames(TD) <- paste0("doc", 1:6)
rownames(TD) <- paste0("w", 1:8)
# 特異値分解（3つの行列の積）。
# 全行列を取り出すのはデータが大きい。だから最初の数行・数列だけ取り出して計算。（近似）
TD_svd <- svd(TD)
options(digits = 3)
TD_svd$u
TD_svd$d
TD_svd$v
t(TD_svd$u[, 1:3]) %*% TD
### 9.6 潜在的意味インデキシングによる分類
install.packages("rgl")
prime.svd <- svd(prime)
prime2 <- t(prime.svd$u[, 1:3]) %*% prime
dim(prime2)
colnames(prime2) <- prime2 %>% colnames() %>%
str_extract("\\d{4}_\\d{2,3}")
cols <- prime2 %>% colnames() %>% str_extract("\\d{3}")
# パッケージ読み込み
library(rgl)
# 別ウィンドウを開き
rgl.open()
# 別ウィンドウを開き
rgl.open()
# 座標を色分けする
rgl.lines(c(-1,1), 0,0, color = "gold")
rgl.lines(0, c(-1,1), 0, color = "gray")
rgl.lines(0,0,c(-1,1), color = "black")
# 3次元空間のカラーを指定し
rgl.bbox(color = "blue", emission = "green")
# 文書名を付置する
rgl.texts(prime2[1,], prime2[2,], prime2[3,],
colnames(prime2), color = cols)
rgl.snapshot(file = "prime.png")
rgl.close()
# 別ウィンドウを開き
rgl.open()
# 座標を色分けする
rgl.lines(c(-1,1), 0,0, color = "gold")
rgl.lines(0, c(-1,1), 0, color = "gray")
rgl.lines(0,0,c(-1,1), color = "black")
# 3次元空間のカラーを指定し
rgl.bbox(color = "blue", emission = "green")
# 文書名を付置する
rgl.texts(prime2[1,], prime2[2,], prime2[3,],
colnames(prime2), color = cols)
rgl.snapshot(file = "prime.png")
